In the case of its Prediction API, Google releases its data mining/prediction tool to users on the basis that their data gets stored on Google servers.7  Effectively, what occurs is that data becomes less distributed and more concentrated within the proprietorial grasp and confines of particular networked corporations.  That stored data also becomes the testing field for a tool enabled with machine learning capacities that is likewise Google’s property. This has major implications for networked cultures and for its political economies.  The Prediction API turns out to be a way of initiating a new pathway for, or at least changing, the usual user-developer assemblage in computational culture. Rather than simply providing content (from user) for an application (by developer), the machine learning architecture of the Prediction API, is driven by a recursive adaptation of the data/content by and into the development of the application itself. There are of course precedents here across all kinds of software development communities – gaming and open-source code for example. But machine learning changes the game plan – it automates the development process making it in some fundamental ways nonparticipatory.